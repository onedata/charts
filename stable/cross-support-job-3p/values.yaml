# Default values for cross-support-job
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

image: onedata/rest-cli:18.02.0-rc7
imagePullPolicy: IfNotPresent

wait_for:
  image: onedata/k8s-wait-for:v1.1
  imagePullPolicy: IfNotPresent

# Specifies if users job should wait for release to start
wait_for_release:
  enabled: true

# Specifies if supports job should wait for luma service to start
wait_for_luma:
  enabled: true

# Specifies if spaces job should wait for groups job to end
wait_for_groups:
  enabled: true

# Specifies if luma job should wait for spaces job to end
wait_for_spaces:
  enabled: true

# Specifies if groups job should wait for users job to end
wait_for_users:
  enabled: true

# You can enable automatic deployment od the environment
# that this chart initializes
onedata-3p:
  enabled: true

# Or manually specify a helm release name of the already
# deployed environment
# releaseName: dev

oneprovider:
  - oneprovider-krakow
  - oneprovider-paris
  - oneprovider-lisbon

spaces:
  - name: "krk-3"
    supports:
      - provider: "krakow"
        storage_name: "ceph"
        size: '1000000000'
  - name: "par-n"
    supports:
      - provider: "paris"
        storage_name: "nfs"
        size: '1000000000'
  - name: "lis-3"
    supports:
      - provider: "lisbon"
        storage_name: "s3"
        size: '1000000000'
  - name: "krk-n-par-3"
    supports:
      - provider: "krakow"
        storage_name: "nfs"
        size: '1000000000'
      - provider: "paris"
        storage_name: "s3"
        size: '1000000000'
  - name: "krk-3-lis-c"
    supports:
      - provider: "krakow"
        storage_name: "s3"
        size: '1000000000'
      - provider: "lisbon"
        storage_name: "ceph"
        size: '1000000000'
  - name: "par-n-lis-c"
    supports:
      - provider: "paris"
        storage_name: "nfs"
        size: '1000000000'
      - provider: "lisbon"
        storage_name: "ceph"
        size: '1000000000'
  - name: "krk-3-par-c-lis-n"
    supports:
      - provider: "krakow"
        storage_name: "s3"
        size: '1000000000'
      - provider: "paris"
        storage_name: "ceph"
        size: '1000000000'
      - provider: "lisbon"
        storage_name: "nfs"
        size: '1000000000'
  - name: "krk-3-par-c-lis-n"
    supports:
      - provider: "krakow"
        storage_name: "s3"
        size: '1000000000'
      - provider: "paris"
        storage_name: "ceph"
        size: '1000000000'
      - provider: "lisbon"
        storage_name: "nfs"
        size: '1000000000'  
  - name: "krk-g"
    supports:
      - provider: "krakow"
        storage_name: "gluster"
        size: '1000000000' 
  - name: "krk-g-par-3"
    supports:
      - provider: "krakow"
        storage_name: "gluster"
        size: '1000000000'
      - provider: "paris"
        storage_name: "ceph"
        size: '1000000000'

# The generalization of nodeSelector.
# Allows for more fine grained controls over which
# nodes are selected by a kubernetes scheduler
# https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
affinity: {}

# List of taints which are tolerated by the pods 
# when nodes are selected by a kubernetes scheduler
# https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
tolerations: {}

# Specify a map of key-value pairs. For the pod 
# to be eligible to run on a node, the node 
# must have each of the indicated key-value pairs as labels
# https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector
nodeSelector: {}